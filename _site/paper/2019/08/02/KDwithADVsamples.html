<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리</title>
  <meta name="description" content="Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리  저자 : Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi  학회 : AAAI 2019  ...">
  
  <meta name="author" content="Sangheon Lee">
  <meta name="copyright" content="&copy; Sangheon Lee 2019">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/monokai-sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  
  <!-- Facebook OGP cards -->
  <meta property="og:description" content="Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리  저자 : Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi  학회 : AAAI 2019  ..." />
  <meta property="og:url" content="http://localhost:4000" />
  <meta property="og:site_name" content="pod3275" />
  <meta property="og:title" content="Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://localhost:4000/assets/logo.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />
  

  
  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리">
  <meta name="twitter:description" content="Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리  저자 : Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi  학회 : AAAI 2019  ...">
  <meta name="twitter:image" content="http://localhost:4000/assets/logo.png">
  <meta name="twitter:url" content="http://localhost:4000">
  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/paper/2019/08/02/KDwithADVsamples.html">
  <link rel="alternate" type="application/rss+xml" title="pod3275" href="http://localhost:4000/feed.xml" />
</head>


  
    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

  

  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
      
      <img src="/assets/logo.png" alt="pod3275">
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
      <i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
        
          
          <li class="nav-link"><a href="/about/">About</a>
          
        
          
        
          
        
          
        
          
          <li class="nav-link"><a href="/posts/">Posts</a>
          
        
          
        
          
          <li class="nav-link"><a href="/typography/">Typography</a>
          
        
          
          <li class="nav-link"><a href="/category/paper/">Paper</a>
          
        
          
        
          
        
      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="post">

<div class="post-header-container " >
  <div class="scrim ">
    <header class="post-header">
      <h1 class="title">Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리</h1>
      <p class="info">by <strong>Sangheon Lee</strong></p>
    </header>
  </div>
</div>

<div class="wrapper">

 <span class="page-divider">
  <span class="one"></span>
  <span class="two"></span>
</span>
 

<section class="post-meta">
  <div class="post-date">August 2, 2019</div>
  <div class="post-categories">
  in 
    
    <a href="/category/Paper">Paper</a>
    
  
  </div>
</section>

<article class="post-content">
  <h1 id="knowledge-distillation-with-adversarial-samples-supporting-decision-boundary-정리">Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리</h1>
<ul>
  <li>저자 : Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi</li>
  <li>학회 : AAAI 2019</li>
  <li>날짜 : 2018.05.15 (last revised 2018.12.14)</li>
  <li>인용 : 4회</li>
  <li>논문 : <a href="https://arxiv.org/pdf/1805.05532.pdf">paper</a></li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>
<h3 id="1-1-knowledge-distillation">1-1. Knowledge Distillation</h3>
<ul>
  <li>딥러닝의 대가 Hinton 교수님의 2015년 <a href="https://arxiv.org/pdf/1503.02531.pdf">논문</a>.</li>
  <li>
    <p>이미 학습된 DNN (Deep Neural Network) 를 이용하여 새로운 DNN을 학습하는 방법.</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/62862896-3b2ff280-bd42-11e9-9db1-416e5bfe5dc3.png" alt="image" /></p>

    <ul>
      <li><strong>이미 학습된 DNN = Teacher network (large)</strong></li>
      <li><strong>새로 학습할 DNN = Student network (small)</strong></li>
      <li>일반적으로 large network에서 small network로 knowledge transfer가 이루어짐.</li>
    </ul>
  </li>
  <li>
    <p><strong>학습 방법</strong></p>

    <p>(1) Teacher network를 학습한다.</p>

    <p>(2) 각 data에 대해, teacher network를 통해 얻는 <em>classification probability</em> (softmax 이전 layer의 output) 를 이용하여 <strong><em>temperature probability</em></strong> 를 계산 및 저장한다.</p>

    <ul>
      <li><strong>Temperature probability</strong></li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/26705935/62863147-ed67ba00-bd42-11e9-8260-7498a0bdab8d.png" alt="image" /></p>

    <ul>
      <li>증류 (Distillation) 에서 temperature 용어를 따옴.</li>
    </ul>

    <p>(3) Student network는 기존 데이터의 <em>original labels</em> 와 (2)에서 구한 <em>temperature probability</em>를 이용하여, <strong><em>KD loss</em></strong> (<strong><em>Knowldege Distillation loss</em></strong>) 를 통해 학습한다.</p>

    <ul>
      <li><strong>KD loss</strong></li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/26705935/62863558-176dac00-bd44-11e9-98ff-594a6a2969ba.png" alt="image" /></p>
  </li>
  <li><strong>결과</strong>
    <ul>
      <li>MNIST 데이터 분류
        <ul>
          <li>Baseline 모델 (3 layers DNN, 784-800-800-10) : 146개의 test error.</li>
          <li>Teacher network (3 layers DNN, 784-1200-1200-10) : 67개의 test error.</li>
          <li>Student network with teacher (Baseline과 같은 구조) : 74개의 test error.</li>
          <li>쌩으로 학습했을 때 (146개) 보다, teacher를 사용했을 때 (74개) 더 성능이 좋음.</li>
        </ul>
      </li>
      <li>MNIST without “3”
        <ul>
          <li>위의 teacher를 이용하여, “3”에 해당하는 데이터 없이 student network를 학습.</li>
          <li>결과는 109개의 test error. 특히 1010개의 “3” test data 중 14개만 틀림.</li>
          <li>Classification probability를 통해 학습하기 때문에, 직접적인 label 데이터가 없어도 <strong>label간의 상관관계를 어느 정도 파악할 수 있음.</strong></li>
        </ul>
      </li>
      <li>MNIST with only “7” and “8”
        <ul>
          <li>“7”과 “8”에 해당하는 데이터만으로 student network를 학습.</li>
          <li>무려 13.2%의 test error. 엄청난 성능을 보임.</li>
        </ul>
      </li>
      <li>결과적으로, student network는 teacher network보다 <strong>작지만 비슷한 성능</strong>을 보일 수 있다.</li>
    </ul>
  </li>
  <li><strong>사용</strong>
    <ul>
      <li>주된 용도: 거의 동등한 성능을 보이면서, <strong>모델의 크기를 줄이고자 할 때 사용.</strong></li>
      <li>Knowledge Distillation으로 학습한 student 모델이, adversarial attack (적대적 공격) 에 강인한 모습을 보인다는 <a href="https://arxiv.org/pdf/1511.04508.pdf">논문</a>이 2016년 발표됨. (<em>Defensive Distillation</em>)</li>
    </ul>
  </li>
  <li><strong>문제점</strong>
    <ul>
      <li>Knowldege Distillation에 관한 기존 연구들은 대부분, 위의 <em>KD loss</em>를 상황 및 데이터에 알맞게 변형한 loss들을 제안하였음.</li>
      <li>이는 단순한 수식의 변형일 뿐더러, 효과 (성능 상승) 가 미미했고, 특정 상황 혹은 데이터에 specific하다는 한계를 보임.</li>
    </ul>
  </li>
  <li>이 논문에서는 더욱 효과적인 Knowledge Distillation 방법을 제안함.
    <ul>
      <li><strong>모델의 결정 경계 (decision boundary) 근처에 있는 데이터</strong>를 이용.</li>
      <li>특히,  <strong>adversarial attack</strong>은 특정 데이터를 모델의 decision boundary 근처로 이동하게 함.</li>
      <li>즉, adversarial attack을 기반으로 <strong>Boundary Supporting Sample (BSS)</strong> 를 생성.</li>
    </ul>
  </li>
</ul>

<h2 id="2-related-works-adversarial-attack">2. Related Works: Adversarial Attack</h2>

<p><img src="https://user-images.githubusercontent.com/26705935/62939101-6d595700-be0b-11e9-93b8-fe562b6f3d4d.png" alt="image" /></p>

<ul>
  <li>2014년 Ian Goodfellow의 <a href="https://arxiv.org/pdf/1412.6572.pdf">논문</a>에서 처음 언급됨.</li>
  <li><strong>Adversarial attack (적대적 공격)</strong> : 입력 이미지에 사람이 구분하기 힘든 noise를 섞음으로써 모델로 하여금 결과를 다르게 하는 것.
    <ul>
      <li>또는 그러한 이미지를 생성하는 방법.</li>
      <li>
        <p>위의 그림: “panda” label을 갖는 그림에 noise를 추가하여 생성된 그림은 “gibbon” label을 가짐. (<a href="https://arxiv.org/pdf/1412.6572.pdf">출처</a>)</p>
      </li>
      <li>생성된 이미지 = adversarial image (example) = natural image + <strong>noise (perturbation)</strong></li>
    </ul>
  </li>
  <li>분류
    <ul>
      <li>공격자의 상황에 따라 두 가지로 나뉨.</li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/26705935/62939044-4569f380-be0b-11e9-920f-b1590c528239.png" alt="image" /></p>

    <p>그림: <a href="https://arxiv.org/pdf/1708.03999.pdf">출처</a></p>

    <p><strong>1. White-box attack</strong></p>

    <ul>
      <li>공격자가 모델의 구조, parameter를 알고, 모델의 loss를 통해 gradient를 계산할 수 있는 경우.</li>
      <li>
        <p>일반적으로, <strong>입력에 따른 모델의 loss의 gradient를 계산하여, 이의 반대 방향으로 입력을 update 하는 방식.</strong></p>
      </li>
      <li>ex) <em>FGSM (Fast Gradient Sign Method)</em> attack</li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/26705935/62938398-f53e6180-be09-11e9-9259-06a3d4b8e027.png" alt="image" /></p>

    <ul>
      <li>$x^* $ = adversarial image, $x$ = natural image, $J(x, y)$ = cross-entropy loss, $\epsilon$ = step size.</li>
      <li>FGSM 이후로 다양한 종류의 attack 기법이 제안됨 (<a href="https://arxiv.org/pdf/1607.02533.pdf">BIM</a>, <a href="https://arxiv.org/pdf/1511.07528.pdf">JSMA</a>, <a href="https://arxiv.org/pdf/1511.04599.pdf">DeepFool</a>, <a href="https://arxiv.org/pdf/1608.04644.pdf">C&amp;W</a>, …)</li>
      <li>직관적인 loss, 안정적인 gradient descent method를 기반으로 하기 때문에, 매우 높은 공격 성공률을 보임.</li>
    </ul>

    <p><strong>2. Black-box attack</strong></p>

    <ul>
      <li>
        <p>공격자가 모델에 대한 모든 정보를 모르고, 오로지 <strong>특정 입력에 대한 결과만 얻을 수 있는 경우. (query)</strong></p>
      </li>
      <li>대표적으로 2가지 방식
        <ul>
          <li><strong>대체 모델 (substitute model) 을 통한 공격</strong> : 원래 모델로부터 query를 날려 얻은 결과로 새로운 구조의 모델 학습 및 공격 (<a href="https://arxiv.org/pdf/1602.02697.pdf">논문</a>)</li>
          <li><strong>Gradient estimation</strong> 을 통한 공격 : 경사의 기울기 구하는 개념으로 gradient를 estimation하여 구함으로써, white-box attack과 같은 방식으로 공격 (<a href="https://arxiv.org/pdf/1805.11770.pdf">논문</a>, 정리)</li>
        </ul>
      </li>
      <li>정확한 수식을 통해 최적화하는 것이 아니기 때문에, 낮은 공격 성공률을 보임.</li>
      <li>하지만 대체 모델을 통한 공격은 대부분의 모델에서 통하기 때문에, 방어하기 어려움.</li>
    </ul>
  </li>
  <li>Discussion
    <ul>
      <li>Adversarial example이 왜 발생하는가 에 대한 많은 분석들이 나옴.</li>
      <li>
        <p>가장 그럴싸한 분석</p>

        <p><img src="https://user-images.githubusercontent.com/26705935/62940728-279e8d80-be0f-11e9-8ce3-1ba257ffa9ee.png" alt="image" /></p>

        <ul>
          <li>Adversarial attack에 강인한 모델 학습 관련한 2017년 <a href="https://arxiv.org/pdf/1706.06083.pdf">논문</a>에서 설명한 그림.</li>
          <li>점: 실제 데이터, 사각형: 사람이 볼 때, 실제 데이터(점)와 구분할 수 없는 영역. (<strong>$l_\infty$ ball</strong>)</li>
          <li>모든 데이터는 $l_\infty$ ball 이 존재하기 때문에, 2번째 그림의 아래 별과 같이 실제로는 파란색인데 초록색 class를 나타내는 데이터가 존재함.</li>
          <li>이것이 adversarial example임.</li>
        </ul>
      </li>
      <li>
        <p>즉, <strong>adverarial example은 모델의 결정 경계 (decision boundary) 근처에 존재함.</strong></p>

        <p><img src="https://user-images.githubusercontent.com/26705935/62941417-ead39600-be10-11e9-9d05-54735dfa9de2.png" alt="image" /></p>

        <ul>
          <li>실제로 white-box attack 과정을 봐도, 매 step 마다 조금씩 움직이다가 모델의 결과가 바뀌는 순간 멈춤.</li>
          <li>다르게 생각하면, <strong>adversarial example은 모델의 decision boundary에 대한 정보를 가지고 있음.</strong></li>
          <li>이러한 정보를 활용하여 Knowledge Distillation을 하면 더 잘 할 것.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="3-proposed-methods">3. Proposed Methods</h2>
<h3 id="boundary-supporting-sample-bss">Boundary Supporting Sample (BSS)</h3>

<p><img src="https://user-images.githubusercontent.com/26705935/62943434-6cc5be00-be15-11e9-9d89-e841e68cfb7e.png" alt="image" /></p>

<ul>
  <li>Student network가 좋은 performance를 갖기 위해선, decision boundary가 teacher network의 decision boundary와 비슷해야 함.</li>
  <li>이를 위해, 모델의 decision boundary 정보를 가지고 있는 데이터를 사용한 Knowldege Distillation 제안.
    <ul>
      <li>일종의 distillation 에서의 data augmentation.</li>
    </ul>
  </li>
  <li><strong>Boundary Supporting Sample (BSS)</strong>: teacher network의 decision boundary 근처에 존재하는 데이터.
    <ul>
      <li>Adversarial example과 비슷한 개념이고, 생성 방식도 비슷하지만, 약간 다름.</li>
    </ul>
  </li>
  <li>제안 기법 4가지 구성
    <ul>
      <li>Iterative scheme to find BSS.</li>
      <li>Knowledge Distillation using BSS.</li>
      <li>BSS 기반 KD와 관련한 다양한 issue들.</li>
      <li>두 모델의 decision boundary의 유사도를 측정하는 metrics.</li>
    </ul>
  </li>
</ul>

<h3 id="3-1-iterative-scheme-to-find-bss">3-1. Iterative Scheme to Find BSS</h3>

<p><img src="https://user-images.githubusercontent.com/26705935/62943986-b1058e00-be16-11e9-81a9-bf75b112fdfd.png" alt="image" /></p>

<ul>
  <li>그림과 같이, teacher network를 기반으로 특정 데이터 (base sample) 로부터 adversairl sample을 생성함.</li>
  <li>
    <p>생성은 white-box attack 방식과 같이, x에 따른 loss의 gradient를 통한 gradient descent method.</p>
  </li>
  <li>
    <p><strong>BSS 생성의 loss function</strong></p>

    <p><img src="https://user-images.githubusercontent.com/26705935/62944397-88ca5f00-be17-11e9-9328-1b50a75fcd93.png" alt="image" /></p>

    <ul>
      <li>b: base sample의 class, k: (b가 아닌) target class.</li>
      <li>$f_b(x)$: x의 classification score (softmax 이전 값들) 중 b class에 해당하는 값.</li>
      <li>
        <p>$f_k(x)$: x의 classification score (softmax 이전 값들) 중 k class에 해당하는 값.</p>
      </li>
      <li>Loss를 최소화함 == b class 확률보다 k class 확률을 높임 == 결과가 k class가 되도록 함.</li>
    </ul>
  </li>
  <li>
    <p><strong>GDM with loss</strong></p>

    <p><img src="https://user-images.githubusercontent.com/26705935/63001739-3e94bc80-beaf-11e9-975a-1bf848828367.png" alt="image" /></p>

    <ul>
      <li>(- 항의 $\eta$ 앞쪽 곱): gradient 크기, (가장 왼쪽 분수): gradient의 방향.</li>
      <li>
        <p>$\epsilon$: loss가 (-)가 되게 하기 위함 == x가 decision boundary를 넘어가게 하기 위함.</p>

        <p><img src="https://user-images.githubusercontent.com/26705935/63002088-16598d80-beb0-11e9-8c26-3fc1989811e6.png" alt="image" /></p>

        <ul>
          <li>테일러 급수를 이용하여 정리해보면 위와 같이 negative loss가 가능해짐.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>GDM step을 멈추는 조건</strong></p>

    <p><img src="https://user-images.githubusercontent.com/26705935/63004025-705c5200-beb4-11e9-8d39-837d74bcdff9.png" alt="image" /></p>

    <ul>
      <li>(a): loss가 (-)가 되면. BSS로 채택함. (accept)</li>
      <li>(b): x가 다른 class 경계 안으로 들어가면. BSS가 아니므로 버림. (reject)</li>
      <li>(c): 너무 많은 step을 가면. 그 쪽 decision boundary가 너무 멀기 때문에 버림. (reject)</li>
    </ul>
  </li>
</ul>

<h3 id="3-2-knowledge-distillation-using-bss">3-2. Knowledge Distillation using BSS</h3>

<ul>
  <li>이미 학습된 teacher classifier ($f_t$) 를 이용한, student classifier ($f_s$) 의 학습 loss $L(n)$</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/26705935/63003443-17d88500-beb3-11e9-899a-6c67bd6af5f7.png" alt="image" /></p>

<ul>
  <li>$L_{cls}(n)$: 원본 데이터 ($(x_n, c_n)$) 의 hard label (true label, $y^{true}$) 을 학습.</li>
  <li>$L_{KD}(n)$: 원본 데이터에 대한 $f_t$의 temperature probability를 학습.</li>
  <li><strong>$L_{BS}(n, k)$: BSS ($\dot{x}_n^k$) 에 대한 $f_t$의 temperature probability를 학습.</strong>
    <ul>
      <li>Decision boundary 정보를 갖는 BSS를 학습에 이용함.</li>
    </ul>
  </li>
  <li>$\alpha, \beta$ 는 loss의 영향력을 나타내는 hyperparameter이고, $p_n^k$는 target class k 가 선택될 확률임. (3-3에서 설명)</li>
</ul>

<h3 id="3-3-various-issues-on-using-bsss">3-3. Various Issues on using BSSs</h3>
<ul>
  <li><strong>How to choose Base Sample?</strong>
    <ul>
      <li>
        <p>모든 데이터를 base sample로 하여 각각의 BSS를 구하는 게 아니고, 괜찮을 것으로 보이는 애들만 선택하여 그에 대한 BSS를 구함.</p>
      </li>
      <li>
        <p>선택되는 base sample $C$ 의 조건:</p>
      </li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/26705935/63004954-8539e500-beb6-11e9-9e22-33313e746688.png" alt="image" /></p>

    <ul>
      <li>즉, BSS를 생성하는 기준인 base sample은 teacher network가 맞추고, (학습 과정 속 현재의) student network도 맞추는 데이터.</li>
      <li>Student network 학습 batch 내에서, 위와 같은 조건을 만족하는 N개의 base sample을 뽑음.</li>
    </ul>
  </li>
  <li><strong>How to choose Target Class k?</strong>
    <ul>
      <li>BSS를 생성하는 과정에서, target class는 아래와 같은 확률 분포 하에서 하나를 sampling 함.</li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/26705935/63005358-4ce6d680-beb7-11e9-9e6b-44397f712582.png" alt="image" /></p>

    <ul>
      <li>$p_n^k$: target class로 k가 선택될 확률.
        <ul>
          <li>Teacher network를 기준으로 base class가 아닌 다른 class들의 probability 비율.</li>
        </ul>
      </li>
      <li>즉, base class와 비슷하다고 판단되는 (가장 가까운) class를 target class로 잡음.</li>
    </ul>
  </li>
</ul>

<h3 id="3-4-metrices-for-similarity-of-decision-boundaries">3-4. Metrices for Similarity of Decision Boundaries</h3>
<ul>
  <li>
    <p>두 decision boundary의 유사도를 측정하는 두 가지 metrics 제안.</p>
  </li>
  <li>
    <p>Magnitude Similarity (<strong><em>MagSim</em></strong>) and Amgle Similarity (<strong><em>AngSim</em></strong>)</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/63005847-4a38b100-beb8-11e9-92bf-f0ee75408fcf.png" alt="image" /></p>

    <ul>
      <li>$\bar{x}_n^{k, t} = \dot{x}_n^{k, t} - x_n$ : Perturbation vector.</li>
      <li>
        <p><em>MagSim</em>, <em>AngSim</em> $\in [0, 1]$, 높을수록 더 유사함.</p>
      </li>
      <li>Base sample로부터 두 모델의 decision boundary까지를 이은 vector들의 크기 및 각도를 비교.</li>
    </ul>
  </li>
</ul>

<h2 id="4-experiments">4. Experiments</h2>
<ul>
  <li>이미지 분류 모델 Knowledge Distillation 실험
    <ul>
      <li>데이터: CIFAR10, ImageNet (32*32), TinyImageNet</li>
    </ul>
  </li>
  <li>비교 기법
    <ul>
      <li>Original: Classification loss (원래 데이터의 true label) 만으로 학습함.</li>
      <li>Hinton: Classification loss + (기존) KD loss 로 학습함.</li>
      <li>FITNET, AT, FSP: Hinton 기법에 부가적인 요소를 추가한 distillation 기법들.</li>
      <li>FSP: layer-wise correlation matrix를 이용하는 기법으로, 실험에서 본 논문 제안 기법과 결합함.</li>
    </ul>
  </li>
  <li>
    <p>Teacher, student network 종류</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/63018844-c2ad6b00-bed4-11e9-870a-3f16ee017063.png" alt="image" /></p>
  </li>
  <li>
    <p><strong>결과 Student 분류 성능</strong></p>

    <p><img src="https://user-images.githubusercontent.com/26705935/63018938-0607d980-bed5-11e9-8dbd-5a2e86555211.png" alt="image" /></p>

    <ul>
      <li>기존의 distillation 기법들에 비해 제안 기법 혹은 FSP와 결합한 기법의 성능이 높음.</li>
    </ul>
  </li>
  <li><strong>Student의 generalization 평가</strong>
    <ul>
      <li>가정: <strong>적은 데이터 만으로 높은 성능을 보인다면 generalization을 잘 한 것이다.</strong></li>
      <li>CIFAR10 학습 데이터의 양을 100%에서 20%까지 줄이면서 student의 성능 평가.</li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/26705935/63019191-98a87880-bed5-11e9-941c-3fd7892a7c4c.png" alt="image" /></p>

    <ul>
      <li>
        <p>그래프: 학습 데이터 양에 따라, Original 기법과 비교한 성능 개선 정도.</p>
      </li>
      <li>
        <p>학습 데이터가 적은 상황에서, student를 그냥 학습한 것에 비한 성능 개선율이 매우 높음.</p>
      </li>
    </ul>
  </li>
  <li><strong>두 decision boundary 간의 유사도 측정</strong>
    <ul>
      <li><em>MagSim</em> and <em>AngSim</em> using CIFAR10 dataset.</li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/26705935/63020465-28035b00-bed9-11e9-8e0e-3f6f477a4048.png" alt="image" /></p>

    <ul>
      <li>Original 기법이나 Hinton 기법에 비해 높은 유사도를 보임.
        <ul>
          <li><em>다른 기법들은 왜 비교하지 않았는가?</em></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>BSS == Adversarial attack?</strong>
    <ul>
      <li>BSS를 찾는 과정을, 기존의 adversarial attack 기법으로 대체하면 어떻게 되는가?</li>
      <li>즉, BSS = adversarial example 이며, distillation에 adversarial training을 적용한 것.</li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/26705935/63019599-ccd06900-bed6-11e9-8ed2-59a12a9b513f.png" alt="image" /></p>

    <ul>
      <li>실험 결과 제안 기법이 기존 adversarial attack을 적용한 것보다 우수한 distillation 성능을 보임.</li>
    </ul>
  </li>
</ul>

<h2 id="5-conclusion">5. Conclusion</h2>
<ul>
  <li><em>Knowledge Distillation</em> 이란 이미 학습된 모델을 이용하여 새로운 모델을 효율적으로 학습하는 기법임.
    <ul>
      <li>일반적으로 이미 학습된 모델 (<em>teacher network</em>) 은 크기가 크고, 새로 학습할 모델 (<em>student network</em>) 은 크기가 작은 것으로 설정함.</li>
      <li>비슷한 성능을 보이면서 <strong>모델의 크기를 줄일 수 있음.</strong></li>
    </ul>
  </li>
  <li>본 논문에서는 모델의 decision boundary 정보를 포함하고 있는 데이터를 생성 및 이용하는, 더욱 효과적인 distillation 기법을 제안함.
    <ul>
      <li>적대적 공격 (Adversarial attack) 개념을 기반으로 <strong><em>Boundary Supporting Sample (BSS)</em></strong> 를 생성.</li>
      <li>생성된 BSS를 이용하여 student network를 학습하는 distillation loss 제안.</li>
      <li>두 모델의 decision boundary의 유사도를 측정하는 두 measures 제안.</li>
    </ul>
  </li>
  <li>Knowledge Distillation 결과 모델의 정확도 및 일반화 성능을 높임.</li>
</ul>

</article>





<section class="rss">
  <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
</section>

<section class="share">
  <span>Share: </span>
  
    
    
      <a href="//twitter.com/share?text=Knowledge+Distillation+with+Adversarial+Samples+Supporting+Decision+Boundary+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F08%2F02%2FKDwithADVsamples.html&via=SangheonLee"
        onclick="window.open(this.href, 'twitter-share', 'width=550,height=255');return false;">
        <i class="fa fa-twitter-square fa-lg"></i>
      </a>
    
    
    
    
    
    
    
  
    
    
    
      <a href="//www.facebook.com/sharer.php?t=Knowledge+Distillation+with+Adversarial+Samples+Supporting+Decision+Boundary+%EC%A0%95%EB%A6%AC&u=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F08%2F02%2FKDwithADVsamples.html"
        onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
        <i class="fa fa-facebook-square fa-lg"></i>
      </a>
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
      <a href="//www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F08%2F02%2FKDwithADVsamples.html"
        onclick="window.open(this.href, 'linkedin-share', 'width=550,height=255');return false;">
        <i class="fa fa-linkedin-square fa-lg"></i>
      </a>
    
    
    
    
  
    
    
    
    
      <a href="//plus.google.com/share?title=Knowledge+Distillation+with+Adversarial+Samples+Supporting+Decision+Boundary+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F08%2F02%2FKDwithADVsamples.html"
        onclick="window.open(this.href, 'google-plus-share', 'width=550,height=255');return false;">
        <i class="fa fa-google-plus-square fa-lg"></i>
      </a>
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
      <a href="//www.pinterest.com/pin/create/button/?description=Knowledge+Distillation+with+Adversarial+Samples+Supporting+Decision+Boundary+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F08%2F02%2FKDwithADVsamples.html&media=http://localhost:4000/assets/header_image.jpg"
        onclick="window.open(this.href, 'pinterest-share', 'width=550,height=255');return false;">
        <i class="fa fa-pinterest-square fa-lg"></i>
      </a>
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
      <a href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent('http://localhost:4000/paper/2019/08/02/KDwithADVsamples.html') + '&title=Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리'; return false">
        <i class="fa fa-reddit-square fa-lg"></i>
      </a>
    
    
  
    
    
    
    
    
    
    
    
  
</section>




<section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'pod3275';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">pod3275</h3>

    <div class="site-navigation">

      <p><strong>Site Map</strong></p>
      <ul class="pages">
        
        
          <li class="nav-link"><a href="/about/">About</a>
        
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/posts/">Posts</a>
        
        
        
        
        
          <li class="nav-link"><a href="/typography/">Typography</a>
        
        
        
          <li class="nav-link"><a href="/category/paper/">Paper</a>
        
        
        
        
        
        
      </ul>
    </div>

    <div class="site-contact">

      <p><strong>Contact</strong></p>
      <ul class="social-media-list">
        <li>
          <a href="mailto:lawlee1@naver.com">
            <i class="fa fa-envelope-o"></i>
            <span class="username">lawlee1@naver.com</span>
          </a>
        </li>

        
          
        
          
          <li>
            <a href="https://www.facebook.com/lawlee1LSH" title="Friend me on Facebook">
              <i class="fa fa-facebook"></i>
              <span class="username">이상헌</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://github.com/pod3275" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
              <span class="username">pod3275</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://www.linkedin.com/in/sangheon-lee-626401181/" title="Connect with me on LinkedIn">
              <i class="fa fa-linkedin"></i>
              <span class="username">Sangheon Lee</span>
            </a>
          </li>
          
        
          
        
          
          <li>
            <a href="https://www.youtube.com/channel/UC4QufB9MMXa3UjEfmZTXMEA" title="Subscribe on YouTube">
              <i class="fa fa-youtube"></i>
              <span class="username">칼바람 뿍뽁이</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://www.instagram.com/sanghoney95/" title="Follow me on Instagram">
              <i class="fa fa-instagram"></i>
              <span class="username">Sanghoney95</span>
            </a>
          </li>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        

      </ul>
    </div>

    <div class="site-signature">
      <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
      <p class="text">pod3275의 머신 러닝 블로그
</p>
    </div>

  </div>

</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>

<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();

  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });
});

</script>




<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-145715679-1', 'auto');
  ga('send', 'pageview', {
    'page': '/paper/2019/08/02/KDwithADVsamples.html',
    'title': 'Knowledge Distillation with Adversarial Samples Supporting Decision Boundary 정리'
  });
</script>



  </body>

</html>
