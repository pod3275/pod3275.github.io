<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>A Convolutional Attention Network for Extreme Summarization of Source Code 정리</title>
  <meta name="description" content="A Convolutional Attention Network for Extreme Summarization of Source Code 정리  저자 : Miltiadis Allamanis, Hao Peng, Charles Sutton  학회 : ICML 2016  날짜 : 2016....">
  
  <meta name="author" content="Sangheon Lee">
  <meta name="copyright" content="&copy; Sangheon Lee 2019">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/monokai-sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  
  <!-- Facebook OGP cards -->
  <meta property="og:description" content="A Convolutional Attention Network for Extreme Summarization of Source Code 정리  저자 : Miltiadis Allamanis, Hao Peng, Charles Sutton  학회 : ICML 2016  날짜 : 2016...." />
  <meta property="og:url" content="http://localhost:4000" />
  <meta property="og:site_name" content="pod3275" />
  <meta property="og:title" content="A Convolutional Attention Network for Extreme Summarization of Source Code 정리" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://localhost:4000/assets/logo.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />
  

  
  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="A Convolutional Attention Network for Extreme Summarization of Source Code 정리">
  <meta name="twitter:description" content="A Convolutional Attention Network for Extreme Summarization of Source Code 정리  저자 : Miltiadis Allamanis, Hao Peng, Charles Sutton  학회 : ICML 2016  날짜 : 2016....">
  <meta name="twitter:image" content="http://localhost:4000/assets/logo.png">
  <meta name="twitter:url" content="http://localhost:4000">
  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/paper/2019/03/30/ConvAttentionSummary.html">
  <link rel="alternate" type="application/rss+xml" title="pod3275" href="http://localhost:4000/feed.xml" />
</head>


  

  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
      
      <img src="/assets/logo.png" alt="pod3275">
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
      <i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
        
          
          <li class="nav-link"><a href="/about/">About</a>
          
        
          
        
          
        
          
        
          
          <li class="nav-link"><a href="/posts/">Posts</a>
          
        
          
        
          
          <li class="nav-link"><a href="/typography/">Typography</a>
          
        
          
          <li class="nav-link"><a href="/tag/out-of-distribution/">out-of-distribution</a>
          
        
          
          <li class="nav-link"><a href="/tag/cnn/">CNN</a>
          
        
          
          <li class="nav-link"><a href="/tag/dropout/">Dropout</a>
          
        
          
          <li class="nav-link"><a href="/category/paper/">Paper</a>
          
        
          
        
          
        
      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="post">

<div class="post-header-container " >
  <div class="scrim ">
    <header class="post-header">
      <h1 class="title">A Convolutional Attention Network for Extreme Summarization of Source Code 정리</h1>
      <p class="info">by <strong>Sangheon Lee</strong></p>
    </header>
  </div>
</div>

<div class="wrapper">

 <span class="page-divider">
  <span class="one"></span>
  <span class="two"></span>
</span>
 

<section class="post-meta">
  <div class="post-date">March 30, 2019</div>
  <div class="post-categories">
  in 
    
    <a href="/category/Paper">Paper</a>
    
  
  </div>
</section>

<article class="post-content">
  <h1 id="a-convolutional-attention-network-for-extreme-summarization-of-source-code-정리">A Convolutional Attention Network for Extreme Summarization of Source Code 정리</h1>
<ul>
  <li>저자 : Miltiadis Allamanis, Hao Peng, Charles Sutton</li>
  <li>학회 : ICML 2016</li>
  <li>날짜 : 2016.02.09 (last revised 2016.02.25)</li>
  <li>인용 : 107회</li>
  <li>논문 : <a href="http://proceedings.mlr.press/v48/allamanis16.pdf">paper</a></li>
</ul>

<h2 id="서론">서론</h2>
<ul>
  <li>Attention 모델
    <ul>
      <li>새로 만들어지는 output을 input의 어떤 부분을 집중하여 만들 것인지 판단.</li>
      <li>각 input마다 attention weight을 줌으로써 새로 생성되는 output이 input의 어떤 부분을 중요하게 생각했는지를 부여함.</li>
      <li>요약문 생성, 번역 등의 task에서 활발히 쓰이고 있다.</li>
    </ul>
  </li>
  <li>Attention 문제
    <ul>
      <li>attention이 특정 부분에 가중치가 쏠림으로써, 그 부분에 연관된 것만 계속해서 생산해낸다.</li>
      <li>OOV(Out-Of-Vocabulary, input corpus에서 자주 등장하는 단어의 set인 vocabulary에 없는 단어) 처리를 [UNK]로 하는 문제.</li>
      <li>이 논문에서는 두 번째 문제에 대한 해결을 다룬다.</li>
    </ul>
  </li>
  <li>Translation-invariante features
    <ul>
      <li>요약, 번역 등의 task에서 input의 중요한 부분은 다른 단어로 대체되는 것이 아니라 <strong>그 단어 자체를 output으로 내도록 해야함.</strong></li>
      <li>OOV 또한 의미를 모르는 단어이므로, input 단어 그대로 output으로 내도록하면 처리할 수 있음.</li>
      <li>기존 attention 모델은 이러한 작업을 잘 못함.</li>
    </ul>
  </li>
  <li>논문의 task
    <ul>
      <li>주어진 source code 내용에 대한 method name(함수 이름)을 예측.</li>
      <li>요약 task의 OOV words에 대한 처리도 가능하도록 함.</li>
    </ul>
  </li>
</ul>

<h2 id="제안-모델">제안 모델</h2>
<ul>
  <li>Attention mechanism : 기존 attention 모델.</li>
  <li><strong>Copy mechansim</strong> : input의 단어를 ouput으로 그대로 복사.</li>
  <li>
    <p>Meta mechanism : attention과 copy의 비율을 조절. (그냥 이름만 그럴싸함)</p>
  </li>
  <li>Copy Convolutional Attentional Model</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/26705935/42079717-5e73e5cc-7bbb-11e8-9bdb-b97c791df81d.png" alt="image" /></p>

<ul>
  <li>CNN으로 attention weight 계산 + GRU(Gated Recurrent Unit)로 output 생성.</li>
  <li>
    <p>1, 2, 3 layer : attention feature 계산</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/42080939-18e16b52-7bbf-11e8-8fd0-97d91db1c5e4.png" alt="image" /></p>

    <ul>
      <li>1st layer : input 전체 c를 padding + convolution (Kl1)</li>
      <li>2nd layer : Convolution + h(t-1)과 element-wise multiplication : 이전 정보</li>
      <li>3rd layer : feature layer : L2를 normalized.</li>
    </ul>
  </li>
  <li>식</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/26705935/42081303-0bc73d1a-7bc0-11e8-8055-b83c3794e0d8.png" alt="image" /></p>
<ul>
  <li>attention weight alpha 계산
    <ul>
      <li>Katt와 convolution 및 softmax로 attention weight인 alpha 계산.</li>
    </ul>
  </li>
  <li>copy weight k 계산
    <ul>
      <li>Kcopy와 convolution 및 softmax로 copy weight인 k 계산. k도 일종의 attention weight임.</li>
    </ul>
  </li>
  <li>lambda : meta-attention
    <ul>
      <li>attention과 copy 사이 비율을 조절. 이것도 Klambda에 의해 학습되는 parameter.</li>
      <li>Pos2Voc : c(input)에서 단어를 copy하는 것.</li>
      <li>ToMap : V(vocabulary)에서 단어를 가져오는 것.</li>
      <li>lambda가 1에 가까우면 copy를 하겠다. 0에 가까우면 attention으로 예측을 하겠다.</li>
    </ul>
  </li>
  <li>Objective function</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/26705935/42081592-cfb4b5d6-7bc0-11e8-9f4a-1e5eefd37c5e.png" alt="image" /></p>

<ul>
  <li>mt : target 단어, ht-1 : 이전 hidden state 값, c : input 전체</li>
  <li>I : binary vector
    <ul>
      <li>target 단어 mt가 input 중 어딘가(ci)에 있으면 1, 아니면 0</li>
    </ul>
  </li>
  <li>u : hyperparameter
    <ul>
      <li>simple attention model의 결과가 UNK이고 target 단어 mt가 input에 있으면 매우 작은 값 exp(-10), 아니면 1.</li>
      <li>Copy를 용이하게 학습하기 위함.</li>
    </ul>
  </li>
  <li>즉, input이 proper noun(고유명사, OOV 등)이면 k(copy)의 확률만 보고, 아니면 alpha+k(attention + copy)의 확률을 봄.</li>
</ul>

<h2 id="실험">실험</h2>
<ul>
  <li>데이터 : Github 오픈 소스의 11개의 java project source code.</li>
  <li>Measure : F1 score
    <ul>
      <li>F1 score : classification에서 사용되는 measure. precision과 recall로 계산.</li>
    </ul>
  </li>
  <li>비교 : tf-idf 모델, biRNN attention 모델</li>
</ul>

<h2 id="결과">결과</h2>

<p><img src="https://user-images.githubusercontent.com/26705935/42082116-249f820a-7bc2-11e8-8f28-09ca72a704ae.png" alt="image" /></p>

<ul>
  <li>conv-attention : attention을 CNN으로 계산 + copy가 없음.</li>
  <li>제안 모델인 copy-attention이 제일 좋았다.</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/26705935/42082190-4cbc1ab4-7bc2-11e8-8dcb-d96cffcef257.png" alt="image" /></p>

<ul>
  <li>use, browser, cache는 OOV : lambda가 1에 가까워지고, 오로지 k만을 보고, 진한 부분에서 copy를 함으로써 output을 얻어낸다.</li>
  <li>set, end는 vocabulary 단어 : lambda가 0에 가까워지고, alpha와 k 모두에서 봄으로써 output을 얻어낸다.</li>
</ul>

<h2 id="결론-및-토의">결론 및 토의</h2>
<ul>
  <li>OOV 혹은 input의 중요한 부분을 <strong>copy 하는 기능</strong>을 attention에 추가 함으로써, OOV에 대한 처리 해결.
    <ul>
      <li><strong>번역 task는 copy가 의미 없을텐데, OOV는 어떻게 처리하는가? 아니면 의미가 있나?</strong></li>
    </ul>
  </li>
  <li>OOV를 다룬 다른 2017년 논문이 있다.
    <ul>
      <li>Attention weight 분포 + OOV 두 문제 모두 다룸.</li>
      <li>Copy라는 방법은 유사하지만, 이 논문은 모든 단어에 대해 alpha(attention) + k(copy) 를 고려하여 output을 냄.</li>
    </ul>
  </li>
</ul>

</article>





<section class="rss">
  <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
</section>

<section class="share">
  <span>Share: </span>
  
    
    
      <a href="//twitter.com/share?text=A+Convolutional+Attention+Network+for+Extreme+Summarization+of+Source+Code+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F03%2F30%2FConvAttentionSummary.html&via=SangheonLee"
        onclick="window.open(this.href, 'twitter-share', 'width=550,height=255');return false;">
        <i class="fa fa-twitter-square fa-lg"></i>
      </a>
    
    
    
    
    
    
    
  
    
    
    
      <a href="//www.facebook.com/sharer.php?t=A+Convolutional+Attention+Network+for+Extreme+Summarization+of+Source+Code+%EC%A0%95%EB%A6%AC&u=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F03%2F30%2FConvAttentionSummary.html"
        onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
        <i class="fa fa-facebook-square fa-lg"></i>
      </a>
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
      <a href="//www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F03%2F30%2FConvAttentionSummary.html"
        onclick="window.open(this.href, 'linkedin-share', 'width=550,height=255');return false;">
        <i class="fa fa-linkedin-square fa-lg"></i>
      </a>
    
    
    
    
  
    
    
    
    
      <a href="//plus.google.com/share?title=A+Convolutional+Attention+Network+for+Extreme+Summarization+of+Source+Code+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F03%2F30%2FConvAttentionSummary.html"
        onclick="window.open(this.href, 'google-plus-share', 'width=550,height=255');return false;">
        <i class="fa fa-google-plus-square fa-lg"></i>
      </a>
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
      <a href="//www.pinterest.com/pin/create/button/?description=A+Convolutional+Attention+Network+for+Extreme+Summarization+of+Source+Code+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F03%2F30%2FConvAttentionSummary.html&media=http://localhost:4000/assets/header_image.jpg"
        onclick="window.open(this.href, 'pinterest-share', 'width=550,height=255');return false;">
        <i class="fa fa-pinterest-square fa-lg"></i>
      </a>
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
      <a href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent('http://localhost:4000/paper/2019/03/30/ConvAttentionSummary.html') + '&title=A Convolutional Attention Network for Extreme Summarization of Source Code 정리'; return false">
        <i class="fa fa-reddit-square fa-lg"></i>
      </a>
    
    
  
    
    
    
    
    
    
    
    
  
</section>




<section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'pod3275';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">pod3275</h3>

    <div class="site-navigation">

      <p><strong>Site Map</strong></p>
      <ul class="pages">
        
        
          <li class="nav-link"><a href="/about/">About</a>
        
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/posts/">Posts</a>
        
        
        
        
        
          <li class="nav-link"><a href="/typography/">Typography</a>
        
        
        
          <li class="nav-link"><a href="/tag/out-of-distribution/">out-of-distribution</a>
        
        
        
          <li class="nav-link"><a href="/tag/cnn/">CNN</a>
        
        
        
          <li class="nav-link"><a href="/tag/dropout/">Dropout</a>
        
        
        
          <li class="nav-link"><a href="/category/paper/">Paper</a>
        
        
        
        
        
        
      </ul>
    </div>

    <div class="site-contact">

      <p><strong>Contact</strong></p>
      <ul class="social-media-list">
        <li>
          <a href="mailto:lawlee1@naver.com">
            <i class="fa fa-envelope-o"></i>
            <span class="username">lawlee1@naver.com</span>
          </a>
        </li>

        
          
        
          
          <li>
            <a href="https://www.facebook.com/lawlee1LSH" title="Friend me on Facebook">
              <i class="fa fa-facebook"></i>
              <span class="username">이상헌</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://github.com/pod3275" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
              <span class="username">pod3275</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://www.linkedin.com/in/sangheon-lee-626401181/" title="Connect with me on LinkedIn">
              <i class="fa fa-linkedin"></i>
              <span class="username">Sangheon Lee</span>
            </a>
          </li>
          
        
          
        
          
          <li>
            <a href="https://www.youtube.com/channel/UC4QufB9MMXa3UjEfmZTXMEA" title="Subscribe on YouTube">
              <i class="fa fa-youtube"></i>
              <span class="username">칼바람 뿍뽁이</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://www.instagram.com/sanghoney95/" title="Follow me on Instagram">
              <i class="fa fa-instagram"></i>
              <span class="username">Sanghoney95</span>
            </a>
          </li>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        

      </ul>
    </div>

    <div class="site-signature">
      <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
      <p class="text">pod3275의 머신 러닝 블로그
</p>
    </div>

  </div>

</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>

<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();

  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });
});

</script>




<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-145715679-1', 'auto');
  ga('send', 'pageview', {
    'page': '/paper/2019/03/30/ConvAttentionSummary.html',
    'title': 'A Convolutional Attention Network for Extreme Summarization of Source Code 정리'
  });
</script>



  </body>

</html>
