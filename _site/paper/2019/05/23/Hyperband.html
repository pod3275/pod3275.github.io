<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리</title>
  <meta name="description" content="Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리  저자 : Lisha Li, Kevin Jamieson, Giulia DeSalvo,Afshin Rostamizadeh, Ameet Talwalka...">
  
  <meta name="author" content="Sangheon Lee">
  <meta name="copyright" content="&copy; Sangheon Lee 2019">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/monokai-sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  
  <!-- Facebook OGP cards -->
  <meta property="og:description" content="Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리  저자 : Lisha Li, Kevin Jamieson, Giulia DeSalvo,Afshin Rostamizadeh, Ameet Talwalka..." />
  <meta property="og:url" content="http://localhost:4000" />
  <meta property="og:site_name" content="pod3275" />
  <meta property="og:title" content="Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://localhost:4000/assets/logo.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />
  

  
  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리">
  <meta name="twitter:description" content="Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리  저자 : Lisha Li, Kevin Jamieson, Giulia DeSalvo,Afshin Rostamizadeh, Ameet Talwalka...">
  <meta name="twitter:image" content="http://localhost:4000/assets/logo.png">
  <meta name="twitter:url" content="http://localhost:4000">
  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/paper/2019/05/23/Hyperband.html">
  <link rel="alternate" type="application/rss+xml" title="pod3275" href="http://localhost:4000/feed.xml" />
</head>


  

  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
      
      <img src="/assets/logo.png" alt="pod3275">
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
      <i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
        
          
          <li class="nav-link"><a href="/about/">About</a>
          
        
          
        
          
        
          
        
          
          <li class="nav-link"><a href="/posts/">Posts</a>
          
        
          
        
          
          <li class="nav-link"><a href="/typography/">Typography</a>
          
        
          
          <li class="nav-link"><a href="/category/paper/">Paper</a>
          
        
          
        
          
        
      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="post">

<div class="post-header-container " >
  <div class="scrim ">
    <header class="post-header">
      <h1 class="title">Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리</h1>
      <p class="info">by <strong>Sangheon Lee</strong></p>
    </header>
  </div>
</div>

<div class="wrapper">

 <span class="page-divider">
  <span class="one"></span>
  <span class="two"></span>
</span>
 

<section class="post-meta">
  <div class="post-date">May 23, 2019</div>
  <div class="post-categories">
  in 
    
    <a href="/category/Paper">Paper</a>
    
  
  </div>
</section>

<article class="post-content">
  <h1 id="hyperband-a-novel-bandit-based-approach-to-hyperparameter-optimization-정리">Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리</h1>
<ul>
  <li>저자 : Lisha Li, Kevin Jamieson, Giulia DeSalvo,Afshin Rostamizadeh, Ameet Talwalkar</li>
  <li>학회 : JMLR 2018</li>
  <li>날짜 : 2016.05.21 (last revised 2018.06.18)</li>
  <li>인용 : 198회</li>
  <li>논문 : <a href="https://arxiv.org/pdf/1603.06560.pdf">paper</a></li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>
<h3 id="1-1-hyperarameter">1-1. Hyperarameter</h3>
<ul>
  <li>모델의 <em>hyperparameter</em>란 학습 과정에 의해 변하지 않는 값으로 모델의 구조, 학습 과정 등을 정의함.
    <ul>
      <li>ex) <em># of layers, # of hidden nodes, learning rate, l2 regularization lambda</em></li>
    </ul>
  </li>
  <li>주어진 모델에 대해 최고의 성능을 내도록 하는 hyperparameter는 모델 type, 데이터 종류 등의 환경에 따라 매우 다름.
    <ul>
      <li>즉, 무슨 환경에서든 항상 최적인 hyperparameter 값은 존재하지 않음.</li>
    </ul>
  </li>
  <li>
    <p>또한 학습을 끝낸 모델의 성능은 hyperparameter 설정에 따라 천차만별임.</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58179450-2fa0d280-7ce3-11e9-8fb1-caf5e08b802c.png" alt="image" /></p>

    <ul>
      <li>그림: 모델의 hyperparameter 설정에 따른 성능의 변동</li>
    </ul>
  </li>
  <li>따라서 특정 기계 학습을 잘 쓰려면, 주어진 환경에서 최적의 hyperparameter 설정은 필수적임.</li>
  <li>기존에는 하나하나 찾아보거나 (소위 trial-and-error) 구간을 나누어서 찾아봤지만 (<a href="https://towardsdatascience.com/grid-search-for-model-tuning-3319b259367e">grid search</a>) 시간이 너무 오래 걸리고, 결과 모델의 성능도 좋진 않음.</li>
  <li>따라서 <strong>모델의 hyperparameter를 최적화하는 기법</strong>에 관한 연구가 진행됨.</li>
</ul>

<h3 id="1-2-hyperparameter-optimization">1-2. Hyperparameter optimization</h3>
<ul>
  <li><strong><em>Bayesian Optimization</em></strong>
    <ul>
      <li>가장 유명한 hyperarameter 최적화 기법</li>
      <li>모델의 hyperarameter에 따른 모델의 성능 함수를 <strong>확률 모델로 regression</strong>하고, 모델의 성능이 높을 것으로 기대되는 hyperarameter 설정 point를 도출하여 탐색함. (한글로 잘 정리되어있는 블로그 <a href="http://research.sualab.com/introduction/practice/2019/02/19/bayesian-optimization-overview-1.html">참고</a>)</li>
      <li>장점 : (이전 정보를 활용하기 때문에) 결과 모델의 성능이 높다.</li>
      <li>단점 : 오래걸린다.
        <ul>
          <li>기본적으로 탐색이 <strong>순차적</strong>으로 진행됨. (탐색하고, 확률 모델 update하고, 다음 탐색 point 찾고, …)</li>
          <li>확률 모델 regression할 때 <em>Gaussian Process Regression</em>을 사용하는데, <em>GP Regression</em>의 time complexity가 관측한 데이터의 세제곱임. (후에 다른 regression 기법을 적용한 <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf"><em>TPE</em></a>가 제안됨)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>저자가 말하는 Bayesian Optimization의 단점
    <ul>
      <li>일반적으로 모델 학습할 때, accuracy 혹은 loss의 변동을 보면서 성능이 높을 모델이다 아니다를 판단할 수 있음.</li>
      <li>그런데 Bayesian Optimization은 <strong>특정 budget(epoch, data등 학습에 투입되는 자원, epoch라고 봐도 무방함)만큼을 반드시 소모</strong>하여 학습을 일정한 수준까지 해야함</li>
      <li>즉, <strong>budget의 낭비</strong>로 인해 탐색 시간이 길다.</li>
    </ul>
  </li>
  <li>새로운 hyperparameter optimization 기법 제시
    <ul>
      <li>모델 학습 과정에서 중간 accuracy 혹은 loss를 보고, <strong>좋을 것으로 예상되는 모델</strong>을 선출 및 선출된 모델에 더 많은 budget을 할당하자.</li>
      <li><em>Hyperparameter optimization problem</em>을 <em>multi-armed bandit problem</em>로 대치.</li>
    </ul>
  </li>
</ul>

<h2 id="2-backgrounds">2. Backgrounds</h2>
<h3 id="2-1-multi-armed-bandit-problem">2-1. Multi-armed bandit problem</h3>
<ul>
  <li>
    <p><em>One-armed bandit</em> (외팔이 강도)</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58404464-211a3880-80a0-11e9-8c1c-0d593fb5cf57.png" alt="image" /></p>

    <ul>
      <li>하나의 레버를 가지고 있는 슬롯머신을 일컫는 말.</li>
    </ul>
  </li>
  <li><strong><em>Multi-armed bandit problem</em></strong>
    <ul>
      <li>여러 개의 슬롯 머신(<em>arms</em>)을 당길 수 있는 상황.</li>
      <li>각각의 슬롯 머신을 당겨서 얻을 수 있는 <em>reward</em>는 서로 다름.</li>
      <li>Reward는 어떤 확률 분포에 의해 draw되는 <em>random variable</em>임.</li>
      <li>제한 시간 내에 (혹은 제한 횟수 내에) 최대의 reward를 얻기 위해서는 슬롯 머신을 어떤 순서로 당겨야 할까?</li>
    </ul>
  </li>
  <li>문제는 arm마다 보상이 다르고, 한 번의 당김에서 하나의 arm의 reward 값만 관측 가능하다는 것.</li>
  <li>
    <p><strong><em>Exploration vs Exploitation</em></strong></p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58408165-38f5ba80-80a8-11e9-95db-efb6bb385e7f.png" alt="image" /> (사진 <a href="https://medium.com/user-experience-ux-experts/you-probably-dont-know-how-to-really-create-great-experiences-e991fbc56767">출처</a>)</p>

    <ul>
      <li>최적화 문제에서 대두되는 두 가지 중요한 요소.</li>
      <li><strong>Exploration</strong>: 더 높은 reward를 내는 슬롯 머신을 찾기 위해, 기존에 당기지 않은 새로운 슬롯 머신을 당겨보는 것.</li>
      <li><strong>Exploitation</strong>: 높은 reward를 얻기 위해, 지금까지 당긴 슬롯 머신 중 가장 높은 reward를 내는 머신을 다시 당기는 것.</li>
      <li>Exploration과 Exploitation은 서로 <strong>trade-off 관계</strong>에 있음.</li>
      <li>따라서 두 가지 요소를 조화롭게 적용하는 최적화 정책(policy)은 필수적임.</li>
    </ul>
  </li>
</ul>

<h3 id="2-2-non-stochastic-best-arm-identification">2-2. Non-stochastic Best Arm Identification</h3>
<ul>
  <li>이 논문은 아니고, 같은 저자의 <a href="https://arxiv.org/pdf/1502.07943.pdf">이전 논문</a> 내용임.</li>
  <li><strong><em>Best arm identification problem</em></strong>
    <ul>
      <li>(<em>Multi-armed banit problem</em>) 제한 시간 내에 최대의 reward 얻기.
–&gt; (<em>Best arm identification problem</em>) 최소의 regret을 내는 arm을 찾기.</li>
    </ul>
  </li>
  <li>문제의 환경 분류: <em>Stochastic</em> and <em>Non-stochastic setting</em>
    <ul>
      <li>
        <p><em>Stochastic setting</em></p>

        <p><img src="https://user-images.githubusercontent.com/26705935/58405341-2d06fa00-80a2-11e9-9d43-47fc93dfa9f8.png" alt="image" /></p>

        <ul>
          <li>각 arm의 regret이 수렴한다.(converge)</li>
          <li>수렴하는 정도(convergence rate)를 알고 있다.</li>
        </ul>
      </li>
      <li>
        <p><em>Non-stochastic setting</em></p>

        <p><img src="https://user-images.githubusercontent.com/26705935/58405393-46a84180-80a2-11e9-9039-fd75a150dcbf.png" alt="image" /></p>

        <ul>
          <li>각 arm의 regret이 수렴한다.</li>
          <li>수렴하는 정도(convergence rate)를 모른다.</li>
          <li>하나의 arm을 당기는 cost는 매우 높다.</li>
        </ul>
      </li>
      <li>
        <p>하이퍼파라미터 최적화 문제는 <em>non-stochastic setting</em>과 유사함.</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="2-3-multi-armed-bandit-problem과-하이퍼파라미터-최적화-문제">2-3. Multi-armed bandit problem과 하이퍼파라미터 최적화 문제</h3>
<ul>
  <li><em>Best arm identification problem</em> –&gt; 하이퍼파라미터 최적화
    <ul>
      <li>arms = 하이퍼파라미터 설정들</li>
      <li>number of pulling the arm = 하이퍼파라미터 설정에 할당되는 budget</li>
      <li>regret = 중간까지 학습한 모델의 (intermediate) validation loss</li>
    </ul>
  </li>
  <li>즉, regret의 최종 수렴 값이 가장 낮은 arm을 찾는다. == 최종 loss가 가장 낮은 하이퍼파라미터 설정을 찾는다.</li>
</ul>

<h2 id="3-proposed-methods">3. Proposed Methods</h2>
<h3 id="3-1-successive-halving-algorithm-sha">3-1. Successive Halving Algorithm (SHA)</h3>
<ul>
  <li>본 논문의 제안 기법은 아니고, 저자들의 <a href="https://arxiv.org/pdf/1502.07943.pdf">이전 논문</a>에서 제안한 하이퍼파라미터 최적화 해결책.</li>
  <li>
    <p><strong>제한된 시간</strong>에서 최소의 loss를 갖는 모델의 하이퍼파라미터 설정을 찾는 것이 목표.</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58406124-e0242300-80a3-11e9-91ab-0033790cb037.png" alt="image" /></p>

    <ol>
      <li>총 탐색에 소요되는 budget 설정. (<em>B</em>)</li>
      <li>n개의 하이퍼파라미터 설정을 랜덤하게 뽑음. (<em>Sk</em>)</li>
      <li>S0의 모델들에 동일한 budget을 할당. (<em>rk</em>)</li>
      <li>학습 및 중간 loss 추출.</li>
      <li>중간 loss를 기준으로, 성능이 좋지 않은 하이퍼파라미터 설정을 반 만큼 버림. (<em>Sk+1</em>)</li>
      <li>하나의 하이퍼파라미터 설정이 남을 때까지 2, 3, 4, 5를 반복.</li>
    </ol>
  </li>
  <li>
    <p>이해가 안가면 숫자를 대입해보면 됨.</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58406834-73118d00-80a5-11e9-86e9-3a9dbf4213ae.png" alt="image" /></p>

    <ul>
      <li>랜덤하게 16개를 뽑아서 1 epoch 만큼 학습하고 좋은 8개를 추출함.</li>
      <li>추출된 8개를 2 epochs 만큼 학습하고 (1 epoch 만큼 더 학습) 좋은 4개를 추출함.</li>
      <li>추출된 4개를 4 epochs 만큼 학습하고 (2 epochs만큼 더 학습) 좋은 2개를 추출함.</li>
      <li>추출된 2개를 8 epochs 만큼 학습하고 (4 epochs만큼 더 학습) 좋은 1개를 추출함. –&gt; 결과!</li>
    </ul>
  </li>
  <li>
    <p>이게 왜 수렴하는가?</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58407899-ac4afc80-80a7-11e9-9001-545d74d87457.png" alt="image" /></p>

    <ul>
      <li>최종 loss(수렴 값)과 현재 loss의 차이에 대한 함수가 <em>non-increasing function</em>이라고 가정.</li>
      <li>특정 <em>t</em> 이상의 budget을 할당하여 학습된 모델의 중간 loss를 비교하는 것만으로도, 최종 loss의 대소관계를 알 수 있다는 것을 증명.</li>
      <li>그렇다면 대소관계가 반영되는 <em>t</em>는 얼마인지 어떻게 알 수 있는가?
        <ul>
          <li>이에 대해 총 소요 budget <em>B</em>를 충분히 크게 잡으면 best arm이 보장된다는 것을 증명함. (생략)</li>
        </ul>
      </li>
      <li>총 소요 budget을 크게 잡기 위해 <em>doubling trick</em>을 적용.
        <ul>
          <li>말 그대로 그냥 <em>B</em>를 2<em>B</em>로 하여 돌리고, 3<em>B</em>로 하여 돌리고, …</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>SHA의 단점
    <ul>
      <li>알고리즘 자체의 hyperparameter(input) : <em>B</em>와 <em>n</em>.</li>
      <li><em>B</em>와 <em>n</em>(정확히는 <em>B/n</em>)에 따라서 <strong>exploration과 exploitation의 비율</strong>이 정해짐.</li>
      <li>따라서 알고리즘 성능을 위해 <em>B</em>와 <em>n</em>이라는 hyperparameter 설정이 굉장히 중요해짐.</li>
    </ul>
  </li>
  <li>그래서 이 논문에서 제안한 것이 “<strong><em>Hyperband</em></strong>” 입니다. (이제야 이 논문을 처음 언급;; )</li>
</ul>

<h3 id="3-2-hyperband">3-2. Hyperband</h3>
<ul>
  <li><em>B</em>와 <em>n</em>의 설정에 따라 성능이 크게 변한다는 SHA의 단점을 보완한 알고리즘.</li>
  <li>
    <p>간단하게, <strong>SHA의 연속</strong>.</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58550865-b573cf00-8249-11e9-90c7-3c0efad3ea5d.png" alt="image" /></p>

    <ol>
      <li>하나의 하이퍼파라미터 설정에 최대로 할당할 budget 설정. (<em>R</em>)</li>
      <li>SHA의 매 step마다 줄어드는 설정의 개수 (혹은 늘어나는 budget의 비율) 설정. (<em>etha</em>, SHA에서는 2)</li>
      <li><em>R</em>과 <em>etha</em>에 따라서 SHA를 반복할 개수 (1 SHA = 1 <em>bracket</em>으로 명명) 및 각 SHA의 처음 step에서 초기화하는 설정의 개수와 할당되는 budget이 계샨됨.</li>
      <li>각 bracket의 SHA 모두 실행.</li>
    </ol>
  </li>
  <li>
    <p>이것도 숫자 대입.</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58551212-7d20c080-824a-11e9-85de-1dccebc5e1af.png" alt="image" /></p>

    <ul>
      <li><em>R</em>=81, <em>etha</em>=3일 때, 총 5번의 SHA를 반복하며 (5 <em>brackets</em>), 각 bracket의 처음 설정 수 및 할당 budget이 달라짐.</li>
    </ul>
  </li>
  <li>특징
    <ul>
      <li><em>B</em>와 <em>n</em>을 설정하지 않고 <em>R</em> 하나만 설정하는 것으로도, <strong>다양한 exploration 및 exploitation 비율을 반영한 search</strong>를 진행할 수 있음.
        <ul>
          <li>특히 <em>R</em>은 한 하이퍼파라미터 설정에 할당되는 최대 budget이기 때문에, 사용자 입장에서 따로 생각할 필요 없이 학습하고 싶은 만큼 값을 설정하면 됨.</li>
          <li><em>R</em>을 한 단위로 보고, 다양하게 설정 가능. (예를 들어, 1<em>R</em> = 10 epochs 학습)</li>
        </ul>
      </li>
      <li>각 bracket들을 <strong>parallel하게 수행</strong>할 수 있음.
        <ul>
          <li><strong>전체 탐색 시간을 단축</strong>시킬 수 있음.</li>
        </ul>
      </li>
      <li>Budget은 학습에 사용되는 자원으로, 제한될 수 있는 다양한 것들이 budget이 될 수 있음.
        <ul>
          <li>학습 iterations(학습 시간), 학습 dataset 개수, 학습 데이터의 feature, 등…</li>
        </ul>
      </li>
      <li><em>etha</em>는 다양한 값이 될 수 있으나, 저자들은 3 또는 4에서 좋은 결과를 얻었다고 말함.</li>
    </ul>
  </li>
</ul>

<h2 id="4-experiments">4. Experiments</h2>
<ul>
  <li>제안 알고리즘인 Hyperband의 유효성 및 우수성 검증.</li>
  <li>비교 모델은 3개의 Bayesian Optimization 기법
    <ul>
      <li><a href="https://github.com/automl/SMAC3"><em>SMAC</em></a>, <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf"><em>TPE</em></a>, <a href="https://github.com/JasperSnoek/spearmint"><em>Spearmint</em></a></li>
      <li>Baseline 모델: random search, random 2X. (사용 budget이 2배)</li>
    </ul>
  </li>
  <li>Budget을 뭘로 잡냐에 따라 3가지 다른 실험을 진행.</li>
</ul>

<h3 id="4-1-budget--학습-iterations">4-1. Budget = 학습 iterations</h3>
<ul>
  <li>8개의 하이퍼파라미터를 가진 Convolutional Neural Network (CNN) 모델을 tuning.</li>
  <li><em>R</em> (budget) 단위 및 <em>etha</em>
    <ul>
      <li>1<em>R</em> = 100 mini-batch iterations</li>
      <li><em>etha</em> = 4</li>
    </ul>
  </li>
  <li>사용 데이터셋 및 <em>R</em>값
    <ul>
      <li>CIFAR10 (<em>R</em>=300), MRBI (<em>R</em>=300), SVHN (<em>R</em>=600)</li>
    </ul>
  </li>
  <li>
    <p>결과</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58552107-89a61880-824c-11e9-9492-9ff8b32315f5.png" alt="image" /></p>

    <ul>
      <li>Random search보다 20배 빠르다.</li>
      <li>다른 하이퍼파라미터 최적화 기법들보다 수렴이 빠르며, 성능이 비슷하거나 좋고, varation도 적었다.</li>
    </ul>
  </li>
</ul>

<h3 id="4-2-budget--학습-dataset-크기">4-2. Budget = 학습 dataset 크기</h3>
<ul>
  <li>6개의 하이퍼파라미터를 가진 ernel-based classification 모델을 tuning.</li>
  <li><em>R</em> (budget) 단위 및 <em>etha</em>
    <ul>
      <li>1<em>R</em> = 100 training data points</li>
      <li><em>etha</em> = 4</li>
    </ul>
  </li>
  <li>사용 데이터셋 및 <em>R</em>값
    <ul>
      <li>CIFAR10 (<em>R</em>=400)</li>
    </ul>
  </li>
  <li>
    <p>결과</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58552420-531ccd80-824d-11e9-85d8-1013b3c89489.png" alt="image" /></p>

    <ul>
      <li>Bayesian Optimizatio보다 30배 빠르다.</li>
      <li>Random search보다 70배 빠르다.</li>
    </ul>
  </li>
</ul>

<h3 id="4-3-budget--feature-subsample">4-3. Budget = feature subsample</h3>
<ul>
  <li>4-2.와 같은 모델 tuning.</li>
  <li><em>R</em> (budget) 단위 및 <em>etha</em>
    <ul>
      <li>1<em>R</em> = 100 features</li>
      <li><em>etha</em> = 4</li>
    </ul>
  </li>
  <li>사용 데이터셋 및 <em>R</em>값
    <ul>
      <li>CIFAR10 (<em>R</em>=1000)</li>
    </ul>
  </li>
  <li>
    <p>결과</p>

    <p><img src="https://user-images.githubusercontent.com/26705935/58552547-9f680d80-824d-11e9-9682-e1c1d72dd770.png" alt="image" /></p>

    <ul>
      <li>Bayesian Optimization보다 6배 빠르다.</li>
    </ul>
  </li>
</ul>

<h2 id="5-conclusion">5. Conclusion</h2>
<ul>
  <li>Hyperparameter optimization 문제를 <strong>non-stochastic best arm identification 문제</strong>로 대응함.
    <ul>
      <li>중간 loss function의 variation이 <em>non-decreasing function</em>이라는 가정.</li>
    </ul>
  </li>
  <li>Hyperband 알고리즘 제안.
    <ul>
      <li>기존에 제안된 Successive Halving Algorithm의 연속.</li>
      <li><strong>다양한 exploration vs exploitation 비율을 반영한 탐색</strong>을 진행.</li>
      <li>결과적으로 Bayesian Optimization보다 <strong>빠른 수렴</strong>이 가능함.</li>
    </ul>
  </li>
  <li>(내가 본)특징
    <ul>
      <li>빠른 수렴이 가능하기 때문에 모델 tuning 시간이 제한된 환경에서 좋은 성능을 효율적으로 낼 수 있음.</li>
      <li>하지만 제한되지 않은 환경에서는 기존 최적화 기법들이 더 높은 성능을 냄.</li>
      <li>이것은 Hyperband의 <strong>bracket (매 SHA를 반복하는 것) 들 간의 정보 교환</strong>이 없기 때문임.</li>
      <li>즉, 기탐색에서 얻은 정보를 활용하지 않기 때문에, 맨 땅에 계속 헤딩하는 식임.</li>
      <li>그렇다고 정보를 교환한다는 것은, 각 bracket을 parallel하게 연산할 수 없기 때문에 탐색 시간이 느려질 것임.</li>
      <li><strong>Bracket간의 정보 교환 vs (parallel 연산을 통한) 탐색 시간 단축</strong> 의 조화가 핵심.
        <ul>
          <li>사실 이를 해결하여 Bayesian Optimization과 Hypeerband를 결합한 <a href="https://arxiv.org/pdf/1807.01774.pdf">BOHB</a> 알고리즘이 이미 제안됨. 참고!</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

</article>





<section class="rss">
  <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
</section>

<section class="share">
  <span>Share: </span>
  
    
    
      <a href="//twitter.com/share?text=Hyperband%3B+A+Novel+Bandit-Based+Approach+to+Hyperparameter+Optimization+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F05%2F23%2FHyperband.html&via=SangheonLee"
        onclick="window.open(this.href, 'twitter-share', 'width=550,height=255');return false;">
        <i class="fa fa-twitter-square fa-lg"></i>
      </a>
    
    
    
    
    
    
    
  
    
    
    
      <a href="//www.facebook.com/sharer.php?t=Hyperband%3B+A+Novel+Bandit-Based+Approach+to+Hyperparameter+Optimization+%EC%A0%95%EB%A6%AC&u=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F05%2F23%2FHyperband.html"
        onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
        <i class="fa fa-facebook-square fa-lg"></i>
      </a>
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
      <a href="//www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F05%2F23%2FHyperband.html"
        onclick="window.open(this.href, 'linkedin-share', 'width=550,height=255');return false;">
        <i class="fa fa-linkedin-square fa-lg"></i>
      </a>
    
    
    
    
  
    
    
    
    
      <a href="//plus.google.com/share?title=Hyperband%3B+A+Novel+Bandit-Based+Approach+to+Hyperparameter+Optimization+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F05%2F23%2FHyperband.html"
        onclick="window.open(this.href, 'google-plus-share', 'width=550,height=255');return false;">
        <i class="fa fa-google-plus-square fa-lg"></i>
      </a>
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
      <a href="//www.pinterest.com/pin/create/button/?description=Hyperband%3B+A+Novel+Bandit-Based+Approach+to+Hyperparameter+Optimization+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Flocalhost%3A4000%2Fpaper%2F2019%2F05%2F23%2FHyperband.html&media=http://localhost:4000/assets/header_image.jpg"
        onclick="window.open(this.href, 'pinterest-share', 'width=550,height=255');return false;">
        <i class="fa fa-pinterest-square fa-lg"></i>
      </a>
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
      <a href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent('http://localhost:4000/paper/2019/05/23/Hyperband.html') + '&title=Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리'; return false">
        <i class="fa fa-reddit-square fa-lg"></i>
      </a>
    
    
  
    
    
    
    
    
    
    
    
  
</section>




<section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'pod3275';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">pod3275</h3>

    <div class="site-navigation">

      <p><strong>Site Map</strong></p>
      <ul class="pages">
        
        
          <li class="nav-link"><a href="/about/">About</a>
        
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/posts/">Posts</a>
        
        
        
        
        
          <li class="nav-link"><a href="/typography/">Typography</a>
        
        
        
          <li class="nav-link"><a href="/category/paper/">Paper</a>
        
        
        
        
        
        
      </ul>
    </div>

    <div class="site-contact">

      <p><strong>Contact</strong></p>
      <ul class="social-media-list">
        <li>
          <a href="mailto:lawlee1@naver.com">
            <i class="fa fa-envelope-o"></i>
            <span class="username">lawlee1@naver.com</span>
          </a>
        </li>

        
          
        
          
          <li>
            <a href="https://www.facebook.com/lawlee1LSH" title="Friend me on Facebook">
              <i class="fa fa-facebook"></i>
              <span class="username">이상헌</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://github.com/pod3275" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
              <span class="username">pod3275</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://www.linkedin.com/in/sangheon-lee-626401181/" title="Connect with me on LinkedIn">
              <i class="fa fa-linkedin"></i>
              <span class="username">Sangheon Lee</span>
            </a>
          </li>
          
        
          
        
          
          <li>
            <a href="https://www.youtube.com/channel/UC4QufB9MMXa3UjEfmZTXMEA" title="Subscribe on YouTube">
              <i class="fa fa-youtube"></i>
              <span class="username">칼바람 뿍뽁이</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://www.instagram.com/sanghoney95/" title="Follow me on Instagram">
              <i class="fa fa-instagram"></i>
              <span class="username">Sanghoney95</span>
            </a>
          </li>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        

      </ul>
    </div>

    <div class="site-signature">
      <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
      <p class="text">pod3275의 머신 러닝 블로그
</p>
    </div>

  </div>

</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>

<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();

  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });
});

</script>




<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-145715679-1', 'auto');
  ga('send', 'pageview', {
    'page': '/paper/2019/05/23/Hyperband.html',
    'title': 'Hyperband; A Novel Bandit-Based Approach to Hyperparameter Optimization 정리'
  });
</script>



  </body>

</html>
